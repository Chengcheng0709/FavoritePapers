#Image to Caption Generation
**Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures**(arXiv)  
[[paper](http://arxiv.org/pdf/1601.03896.pdf)]  

**Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books** (Arxiv,2015)  
*Yukun Zhu@1, Ryan Kiros@1, Richard Zemel@1, Ruslan Salakhutdinov@1, Raquel Urtasun@1, Antonio Torralba@2, Sanja Fidler@1* (@1:University of Toronto,@2:Massachusetts Institute of Technology)   
[[paper](http://arxiv.org/abs/1506.06724)]
[[code](https://github.com/ryankiros/neural-storyteller)]
[[data](http://www.cs.toronto.edu/~mbweb/)]  

**Show, Attend and Tell: Neural Image Caption Generation with Visual Attention**  
*Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio*  
[[paper](http://jmlr.org/proceedings/papers/v37/xuc15.pdf)]  
[[supplementary](http://jmlr.org/proceedings/papers/v37/xuc15-supp.pdf)]  
[[code](https://github.com/kelvinxu/arctic-captions)]  
[[video introduction](https://www.youtube.com/watch?v=kLWRKr4PT_E)]  
[[slide](http://www.slideshare.net/eunjileee/show-attend-and-tell-neural-image-caption-generation-with-visual-attention)]  

**Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models** (TACL, 2015)  
*Ryan Kiros, Ruslan Salakhutdinov, Richard Zemel*  
[[paper](http://arxiv.org/abs/1411.2539)]  
[[demo](http://deeplearning.cs.toronto.edu/i2thttp://deeplearning.cs.toronto.edu/i2t)]  
[[code](https://github.com/ryankiros/visual-semantic-embedding)]  

##Survey
[[link](http://www.slideshare.net/metaps_JP/deep-learning-50383383)]  

