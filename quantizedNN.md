#Quantized Neural Networks

**Bitwise Neural Networks**  
*Minje Kim, Paris Smaragdis*  
[[paper](http://arxiv.org/abs/1601.06071)]  
[[reddit](https://www.reddit.com/r/MachineLearning/comments/42tfjw/bitwise_neural_networks/)]  
real-value learning -> binarized learning

**Deep Compression**
*Song Han, Huizi Mao, William J. Dally*  
[[paper](http://arxiv.org/abs/1510.00149)]  
[[link](http://web.stanford.edu/class/ee380/Abstracts/160106-slides.pdf)]  

**Deep Learning with Limited Numerical Precision**  
*Suyog Gupta, Ankur Agrawal, Kailash Gopalakrishnan, Pritish Narayanan(IBM research)*  
[[paper](http://jmlr.org/proceedings/papers/v37/gupta15.pdf)]  

**Neural Networks with Few Multiplications**  
*Zhouhan Lin, Matthieu Courbariaux, Roland Memisevic, Yoshua Bengio*  
[[paper](http://arxiv.org/abs/1510.03009)]  
[[code](https://github.com/MatthieuCourbariaux/BinaryConnect)]  
[[blogpost](http://nuit-blanche.blogspot.jp/2015/10/neural-networks-with-few.html)]  
[[some related video?](https://www.youtube.com/watch?v=DleXA5ADG78)]  
[[GitXiv](http://gitxiv.com/posts/FE8DeEN97Z6GR5Kvq/neural-networks-with-few-multiplications)]  
quantized weight learning

**BinaryConnect: Training Deep Neural Networks with binary weights during propagations**  
*Matthieu Courbariaux, Yoshua Bengio, Jean-Pierre David*  
[[paper](http://arxiv.org/abs/1511.00363)]  
[[code](https://github.com/hantek/BinaryConnect)]  
[[code2](https://github.com/hantek/binary_conv)]  

**Deep learning with low precision multipliers**  
[[paper](http://arxiv.org/abs/1412.7024)]  
[[code](https://github.com/MatthieuCourbariaux/deep-learning-multipliers)]  
[[GitXiv](http://gitxiv.com/posts/tmytRaBgBahjC7Y4G/low-precision-storage-for-deep-learning)]  

