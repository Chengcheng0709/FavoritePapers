#Image Generation  
**Learning What and Where to Draw(NIPS2016)**  
*Scott Reed et al.*  
[[paper](http://www.scottreed.info/files/nips2016.pdf)]  
[[code](https://github.com/reedscot/nips2016)]  

**Generating Videos with Scene Dynamics(NIPS2016)**  
*Carl Vondrick, Hamed Pirsiavash, Antonio Torralba*  
[[project](http://web.mit.edu/vondrick/tinyvideo/)]  
[[code](https://github.com/cvondrick/videogan)]  

**Generative Visual Manipulation on the Natural Image Manifold(ECCV2016)**  
*Jun-Yan Zhu, Philipp Kr¨ahenb¨uhl, Eli Shechtman, and Alexei A. Efros1*  
[[project](https://people.eecs.berkeley.edu/~junyanz/projects/gvm/)]  

**Deep Generative Model(DL summer school)**    
[[slide](http://www.cs.toronto.edu/~rsalakhu/talk_Montreal_2016_Salakhutdinov.pdf)]   

**Instance Normalization: The Missing Ingredient for Fast Stylization**  
[[paper](https://arxiv.org/abs/1607.08022)]  

**Spatial Transformer Networks(NIPS2015)**  
[[paper](https://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)]  
[[video](https://www.youtube.com/watch?v=Ywv0Xi2-14Y)]  
[[code](https://github.com/skaae/transformer_network)]  

**Stochastic Backpropagation and Approximate Inference in Deep Generative Models**  
[[paper](http://arxiv.org/pdf/1401.4082v3.pdf)]  
missing valueに対する生成モデルによる修復について載っている(付録F)  

**Anticipating Visual Representations from Unlabeled Video(CVPR2016)**
[[paper](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Vondrick_Anticipating_Visual_Representations_CVPR_2016_paper.pdf)]  

**Conditional Image Generation with PixelCNN Decoders**  
[[paper](http://arxiv.org/abs/1606.05328)]  
[[slide(ja)](http://www.slideshare.net/beam2d/pixel-recurrent-neural-networks?ref=http://connpass.com/event/34960/presentation/)]  

**Synthesizing the preferred inputs for neurons in neural networks via deep generator networks**  
*Anh Nguyen, Alexey Dosovitskiy, Jason Yosinski, Thomas Brox, Jeff Clune*  
[[paper](http://arxiv.org/abs/1605.09304)]  
[[CreativeAi](http://www.creativeai.net/posts/Mv4WG6rdzAerZF7ch/synthesizing-preferred-inputs-via-deep-generator-networks)]  
[[projectpage](http://www.evolvingai.org/synthesizing)]  
[[code](https://github.com/Evolving-AI-Lab/synthesizing/)]  

**Artistic style transfer for videos**  
*Manuel Ruder, Alexey Dosovitskiy, Thomas Brox*  
[[paper](http://arxiv.org/abs/1604.08610)]  
[[video](https://www.youtube.com/watch?v=vQk_Sfl7kSc)]  

**Perceptual Losses for Real-Time Style Transfer and Super-Resolution**  
*Justin Johnson, Alexandre Alahi, Li Fei-Fei*  
[[paper](http://arxiv.org/pdf/1603.08155.pdf)]  

**A Theory of Generative ConvNet(ICML2016)**  
*Jianwen Xie, Yang Lu, Song-Chun Zhu, Ying Nian Wu*  
[[paper](http://jmlr.org/proceedings/papers/v48/xiec16.pdf)]  
[[ArXiv](http://arxiv.org/abs/1602.03264)]  

**Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning**  
*William Lotter, Gabriel Kreiman, David Cox*  
[[paper](https://arxiv.org/abs/1605.08104)]  
[[blog](http://karasunoblog.blog20.fc2.com/blog-entry-46.html)]  
[[project](https://coxlab.github.io/prednet/)]  
[[code](https://github.com/coxlab/prednet)]  

**Towards Conceptual Compression(Arxiv)**  
*Karol Gregor, Frederic Besse, Danilo Jimenez Rezende, Ivo Danihelka, Daan Wierstra*  
[[link](https://arxiv.org/abs/1604.08772)]  

**Deep Generative Models with Stick-Breaking Priors**  
*Eric Nalisnick, Padhraic Smyth*  
[[paper](http://arxiv.org/abs/1605.06197)]  

**Generative Adversarial Text to Image Synthesis(ICML2016)**  
*Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, Honglak Lee*  
[[paper](http://jmlr.org/proceedings/papers/v48/reed16.pdf)]  
[[ArXiv](http://arxiv.org/abs/1605.05396)]
[[supplements(download)](http://jmlr.org/proceedings/papers/v48/reed16-supp.zip)]  
[[code](https://github.com/reedscot/icml2016)]  
[[slide(ja)](http://niconare.nicovideo.jp/watch/kn1626)]  

**Colorful Image Colorization**   
*Richard Zhang, Phillip Isola, Alexei A. Efros*  
[[GitXiv](http://gitxiv.com/posts/4HvQAMvaLa94Wroxo/colorful-image-colorization)]  

Generating Abstract Patterns with TensorFlow[[blog](http://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/)]  

**Neural network based model for visual-motor integration learning of robot's drawing behavior: Association of a drawing motion from a drawn image**  
*K. Sasaki, Tjandra, K. Noda, K. Takahashi, T. Ogata*  
[[paper](http://ieeexplore.ieee.org/xpl/abstractAuthors.jsp?arnumber=7353752&abstractAccess=no&userType=inst)]   
[[master](http://www.ias.sci.waseda.ac.jp/GraduationThesis/2014_summary/5113E010_s.pdf)]  

**Generative Image Modeling using Style and Structure Adversarial Networks**  
*Xiaolong Wang, Abhinav Gupta*  
[[paper](http://arxiv.org/abs/1603.05631)]  

**子供の言語獲得と機械の言語獲得**  
[[slide](http://www.slideshare.net/unnonouno/ss-59660836)]  

**One-Shot Generalization in Deep Generative Models**  
*Danilo Jimenez Rezende, Shakir Mohamed, Ivo Danihelka, Karol Gregor, Daan Wierstra* 
[[paper](http://jmlr.org/proceedings/papers/v48/rezende16.pdf)]  
[[ArXiv](http://arxiv.org/abs/1603.05106)]  
[[video](https://www.youtube.com/watch?v=ptLdYd8FXRA&feature=youtu.be)]  
[[video](https://www.youtube.com/watch?v=HkDxmnIfWIM)]  
[[video](https://www.youtube.com/watch?v=6S6Tx_OtvnA)]  
[[video](https://www.youtube.com/watch?v=HQEI2xfTgm4)]  
[[video](https://www.youtube.com/watch?v=qb2-73OHuWA)]  
[[video](https://www.youtube.com/watch?v=281wqqkmAuw)]  
[[video](https://www.youtube.com/watch?v=W0R394wEUqQ)]  

**Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks**  
*Alex J. Champandard*  
[[GitXiv](http://gitxiv.com/posts/iD8CfPqfgqixC53w8/neural-doodle)]  
[[paper](http://arxiv.org/abs/1603.01768)]  
[[code](https://github.com/alexjc/neural-doodle/)]  
[[faster code](https://github.com/DmitryUlyanov/fast-neural-doodle)]  

**Texture Networks: Feed-forward Synthesis of Textures and Stylized Images(ICML2016)**  
*Dmitry Ulyanov, Vadim Lebedev, Andrea Vedaldi, Victor Lempitsky*  
[[paper](http://jmlr.org/proceedings/papers/v48/ulyanov16.pdf)]  
[[supplement](http://jmlr.org/proceedings/papers/v48/ulyanov16-supp.pdf)]  
[[ArXiv](http://arxiv.org/abs/1603.03417)]  
[[code](https://github.com/DmitryUlyanov/texture_nets)]  
 
**Variational Gaussian Process**(ICLR2016)    
*Dustin Tran, Rajesh Ranganath, David M. Blei*  
[[paper](http://arxiv.org/abs/1511.06499v2)]  

**Auxiliary Deep Generative Models(ICML2016)**  
*Lars Maaløe, Casper Kaae Sønderby, Søren Kaae Sønderby, Ole Winther*  
[[paper](http://jmlr.org/proceedings/papers/v48/maaloe16.pdf)]  
[[ArXiv](http://arxiv.org/abs/1602.05473)]  
[[GitXiv](http://gitxiv.com/posts/XNf7oNqe47RhBzivu/auxiliary-deep-generative-models)]  

**Generating images with recurrent adversarial networks**(Arxiv2016)  
*Daniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, Roland Memisevic*  
[[paper](http://arxiv.org/abs/1602.05110)]  
DRAW with GAN.GANはモデルの良さを評価するのが難しいという難点があるが、これをBattle between GANs（2つのGANを戦わせる）という方法で評価することを試みた。  
M1={G1,D1},M2={G2,D2}を用いて{G1,D1},{G1,D2},{G2,D1},{G2,D2}の4モデルで学習.r_test(testset classification error)が1に近いときにGeneratorのclassification errorを比較して、生成モデルを評価しているが、これDiscreminatorの分布を同じにした方が良いのでは、と思った（同じにするという意味で）。

**Deep Visual Analogy-Making**  
[[code](https://github.com/carpedm20/visual-analogy-tensorflow)]  

**Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis**(arXiv)  
*Chuan Li, Michael Wand*  
[[paper](http://arxiv.org/abs/1601.04589)]  
[[GitXiv](http://gitxiv.com/posts/DtC4Zwz3kqCDBHFD7/combining-markov-random-fields-and-convolutional-neural)]  
[[code](https://github.com/awentzonline/image-analogies)]  

**Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis**  
*Jimei Yang Scott Reed Ming-Hsuan Yang1 Honglak Lee*  
[[paper](http://www-personal.umich.edu/~reedscot/nips15_rotator_final.pdf)]  

**Attribute2Image: Conditional Image Generation from Visual Attributes**(arXiv)
[[paper](http://arxiv.org/abs/1512.00570)]  
[[demo video](https://www.youtube.com/watch?v=njSluPk48KM)]  

**Joint Embeddings of Shapes and Images via CNN Image Purification**  
*3D shapes and 2D images searchable from each other*  
[[GitXiv](http://gitxiv.com/posts/PqYNSNaztGgjRNv9t/joint-embeddings-of-shapes-and-images-via-cnn-image)]  

**sketch-rnn**  
*Recurrent Net Dreams Up Fake Chinese Characters in Vector Format with TensorFlow*  
[[GitXiv]((http://gitxiv.com/posts/TPq9xYai34hANyG3r/sketch-rnn)]  

**Improving Semi-Supervised Learning with Auxiliary Deep Generative Models**  
*Deep generative models based upon continuous variational distributions parameterized by deep nets*  
[[Gitxiv](http://gitxiv.com/posts/BdMD74rApubKLGALJ/improving-semi-supervised-learning-with-auxiliary-deep)]  

**Human-level concept learning through probabilistic program induction**  
[[link](http://science.sciencemag.org/content/350/6266/1332)]  

**ADVERSARIAL AUTOENCODERS**  
*Alireza Makhzani* (University of Toronto)  
*Jonathon Shlens & Navdeep Jaitly & Ian Goodfellow* (Google Brain)  
[[paper](http://arxiv.org/pdf/1511.05644v1.pdf)]  
[[article](http://www.inference.vc/adversarial-autoencoders)]  
[[theano](https://github.com/mikesj-public/dcgan-autoencoder)]  
[[blog](http://musyoku.github.io/2016/02/22/adversarial-autoencoder/)]  
[[chainer](https://github.com/musyoku/adversarial-autoencoder)]  

**Autoencoding beyond pixels using a learned similarity metric**   
[[paper](http://arxiv.org/pdf/1512.09300.pdf)]  
[[chainer](https://github.com/stitchfix/fauxtograph)]

**Texture Synthesis Using Convolutional Neural Networks**  (NIPS2015)  
*Leon Gatys, Alexander S. Ecker, Matthias Bethge* (University of Tubingen)  
[[paper](http://papers.nips.cc/paper/5633-texture-synthesis-using-convolutional-neural-networks)]  
[[code](https://github.com/leongatys/DeepTextures)]  

**Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks** (Arxiv,ICLR2016 under review)  
*Alec Radford@1, Luke Metz@1, Soumith Chintala@2* (@1:indico Research,@2:Facebook AI Research)  
[[paper](http://arxiv.org/abs/1511.06434)]  
[[code theano](https://github.com/Newmu/dcgan_code/tree/gh-pages?utm_content=buffer29989&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)]  
[[code torch](https://github.com/soumith/dcgan.torch)]  
[[code chainer](https://github.com/mattya/chainer-DCGAN)]  
[[qiita code chainer2](http://qiita.com/rezoolab/items/5cc96b6d31153e0c86bc)]  
[[some imformation 1](https://plus.google.com/+SoumithChintala/posts/MCtDVqsef6f)]  
[[GAN slide](http://www.cs.toronto.edu/~dtarlow/pos14/talks/goodfellow.pdf)]  
[[Tensorflow](https://github.com/nivwusquorum/tf-adversarial/blob/master/Adversarial-LSUN.ipynb)]  
[[GitXiv](http://gitxiv.com/posts/pNosr4Zrgn8uPEi9R/unsupervised-representation-learning-with-deep-convolutional)]  

**GENERATING IMAGES FROM CAPTIONS WITH ATTENTION** (Arxiv,ICLR2016 under review)  
*Elman Mansimov, Emilio Parisotto, Jimmy Lei Ba & Ruslan Salakhutdinov* (University of Toronto)  
[[paper](http://arxiv.org/pdf/1511.02793v1.pdf)]  
[[slide](http://www.cs.toronto.edu/~emansim/nipsram2015/presentation_nipsram2015.pdf)  
[[reddit](https://www.reddit.com/r/MachineLearning/comments/3safll/generating_images_from_captions_with_attention/)]  
[[code](https://github.com/emansim/text2image)]  

**Inverting Visual Representations with Convolutional Networks** (Arxiv)  
*Alexey Dosovitskiy, Thomas Brox* (University of Freiburg)  
[[paper](http://arxiv.org/abs/1506.02753)]  

**DRAW: A Recurrent Neural Network For Image Generation**  (ICML2015)  
*Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, Daan Wierstra* (Google DeepMind)  
[[paper](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2015_gregor15.pdf)]  
[[demo](https://www.youtube.com/watch?v=Zt-7MI9eKEo)]  
[[introduction slide from www](http://people.ee.duke.edu/~lcarin/Zhe10.2.2015.pdf)]  
[[reddit](https://www.reddit.com/r/MachineLearning/comments/2w90dk/draw_a_recurrent_neural_network_for_image)]  
[[reproduced code1](https://github.com/jbornschein/draw)]  
[[reproduced code2](https://github.com/skaae/lasagne-draw)]*doesn't work well...?*  
[[reproduced code3](https://github.com/uaca/deepy)] 
[[blog](http://evjang.com/articles/draw)]  

**Unveiling the Dreams of Word Embeddings: Towards Language-Driven Image Generation**(Arxiv2015)  
*Angeliki Lazaridou, Dat Tien Nguyen, Raffaella Bernardi, Marco Baroni*  
[[paper](http://arxiv.org/abs/1506.03500)]  

**Laplacian Pyramid of Generative Adversarial Networks**  
[[project](http://soumith.ch/eyescream/)]  
[[slideshare](http://www.slideshare.net/hamadakoichi/laplacian-pyramid-of-generative-adversarial-networks-lapgan-nips2015-reading-nipsyomi)]  
 
**Semi-supervised Learning with Deep Generative Models**  (NIPS2014)  
*D.P. Kingma, D.J. Rezende, S. Mohamed, M. Welling* (Universiteit van Amsterdam)  
[[paper](http://papers.nips.cc/paper/5352-semi-supervised-learning-with-deep-generative-models.pdf)]  
[[code](https://github.com/dpkingma/nips14-ssl)]  
[[slide](https://ift6266h15.files.wordpress.com/2015/04/20_vae.pdf)]  
[[slide2](http://deeplearning.jp/wp-content/uploads/2014/04/dl_hacks2015-04-21-iwasawa1.pdf)]  
[[slide3](http://www.slideshare.net/beam2d/semisupervised-learning-with-deep-generative-models)]  

**Stochastic Gradient VB and the Variational Auto-Encoder** (ICLR2014)  
*D.P. Kingma, M. Welling* (Universiteit van Amsterdam)  
[[paper](http://dpkingma.com/wordpress/wp-content/uploads/2014/10/iclr14_vae.pdf)]  
[[chainer code](https://github.com/takerum/vae)]  
[[chaienr code2](http://nbviewer.ipython.org/gist/duschendestroyer/a41fcab5f7f9ffa45387)]  
[[chainer code3](https://github.com/yuichiro-s/chainer-vae)]  

#Object Retrieval  
**Natural Language Object Retrieval**  
*Ronghang Hu, Huazhe Xu, Marcus Rohrbach, Jiashi Feng, Kate Saenko, Trevor Darrell*  
[[project](http://ronghanghu.com/object-retrieval/)]  
[[paper](http://arxiv.org/abs/1511.04164)]  
[[code](coming soon?)]  
